{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red27\green29\blue31;\red255\green255\blue255;
\red52\green52\blue52;\red25\green25\blue25;\red42\green55\blue62;\red245\green245\blue245;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c14118\c15294\c16078;\cssrgb\c100000\c100000\c100000;
\cssrgb\c26667\c26667\c26667;\cssrgb\c12941\c12941\c12941;\cssrgb\c21569\c27843\c30980;\cssrgb\c96863\c96863\c96863;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}}
\margl1440\margr1440\vieww25400\viewh16000\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\b\fs36 \cf0 DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\cf2 \
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls1\ilvl0\cf2 {\listtext	\'95	}\expnd0\expndtw0\kerning0
High-level overview of the paper\'a0(main contributions)\
\pard\pardeftab720\partightenfactor0
\cf0 \kerning1\expnd0\expndtw0 	Task: Semantic image segmentation.\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 	\cf3 \cb4 \expnd0\expndtw0\kerning0
\'93Semantic segmentation" attempts to ..\cf0 \cb1 \kerning1\expnd0\expndtw0 \
\pard\pardeftab720\partightenfactor0
\cf0 	Three main contributions: Convolution with upsampled filters, or \'91atrous convolution\'92, powerful tool in dense prediction tasks. \
	Atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales.\
	To improve the localization of object boundaries by combining methods from DCNNs and fully connected CRF.\
	Causes and motivation in suggesting these contributions.\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Problem statement and motivation\'a0(clear definition of the problem, why it is interesting and important)\cf0 \kerning1\expnd0\expndtw0 \
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf0 	Challenges in the application of DCNNs to semantic image segmentation.. \
			(1) CNN -> classification, dense prediction\
			(2) other challenges:: max-pooling: add skip-layers or use dilated filtering.\
			\cf2 \expnd0\expndtw0\kerning0
Check figures for max pooling: Spectral Repr. for CNN\
			\cf0 \kerning1\expnd0\expndtw0 \
	How these challenges are tackled by the proposed method, contributions.\
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf0  FCN -> seminal work on dense prediction, casting the fully connected layer as a convolution layer(check FCN Slides)\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls3\ilvl0\cf2 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Connections with other work\'a0(how it relates to other approaches, its similarities and differences)\
\pard\pardeftab720\partightenfactor0
\cf0 \kerning1\expnd0\expndtw0 	R-CNNs\
	Structured prediction techniques using hand-crafted features.\
	DCNN-based methods: briefly detail \
	1- Bottom-up methods: \
		(Am I supposed to dig into papers?) briefly detail\
		bounding box proposals and masked regions incorporating shape information into the classification process.\
		Superpixel methods.\
	2- Dense image labeling + independant segmentation \
	3- Methods directly providing dense category-level pixel labels like Fully Convolutional Networks \
	\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls4\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Key technical ideas\'a0(overview of the approach)\
\ls4\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\'95	}\cf0 Inspirations from fully-connected network paper.\
\pard\pardeftab720\partightenfactor0
\ls4\ilvl0\cf2 		\cf0 Spatial pyramid pooling vs. DCNN layers for multiple scaled versions.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls4\ilvl0\cf2 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 	Focus on sections 3.1, 3.2\
	Dilated atrous filters vs. \cf0 \kerning1\expnd0\expndtw0 deconvolutional layers..\
	How to perform atrous convolution?\
	How ASPP method is performed? ( inspirations: R-CNN spatial pyramid pooling)\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\tx1440\pardeftab720\sl280\partightenfactor0
\cf2 	\cf0 \kerning1\expnd0\expndtw0 DCNNs and CRFs: \
		Treats every pixel as a CRF node receiving unary potentials by the DCNN. Crucially, the Gaussian CRF potentials in the fully connected CRF 		model of [22] that we adopt can capture long-range dependencies and at the same time the model is amenable to fast mean field inference.\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 	Model, network design considerations, Atrous Filter design, \cf0 \kerning1\expnd0\expndtw0 Atrous spatial pyramid pooling (ASPP) design, \
	How to apply transfer learning using VGGnet, Resnet etc?\
	Fully CRF inference details. (issues time and quality(fully connected))\
	Mean-Field approximation using message-passing approach. How to achieve efficient inference using CRF?\
	Why is fully connected CRF utilized?\
\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls5\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Experimental set-up\'a0(datasets, evaluation metrics, applications)\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 	\cf0 \kerning1\expnd0\expndtw0 PASCAL VOC 2012 semantic segmentation benchmark, PASCAL-Context, PASCAL Person-Part [36], and Cityscapes [37]\
	Pixel intersection-over-union (IOU)\
	Training/network parameters. Explain step by step\
	Experimental Results - 1 slide for each subsection\
\
Extensions:\
	MSC: Employing multi-scale inputs with max fusion. \
	COCO: Models pre-trained on MS-COCO.\
	Aug: Data augmentation by randomly rescaling inputs\
	Resnet\
	Qualitative/Quantitative Results\
\pard\pardeftab720\partightenfactor0
\cf0 	Other methods using CRFs with DCNNs	(jointly)	\
\
\
	- iteration of the dense CRF mean field inference [22] by convolutional layers with learnable filters [63] replace the bilateral filtering module used in mean field inference with a faster domain transform module\
	- Weaker supervision has been pursued in a number of papers, relaxing the assumption that pixel-level semantic annotations are available for 	the whole training set.\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls6\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Strengths and weaknesses\'a0(discussion of the results obtained)\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 	Speed, accuracy, \
	Qualitative result improvements when CRF is used.\
\pard\pardeftab720\sl300\sa240\partightenfactor0
\cf2 	it needs to perform convolutions on a large number of de- tailed (high-resolution) feature maps that usually have high- dimensional features, which are computational expensive. 	\
	Moreover, a large number of high-dimensional and high- resolution feature maps also require huge GPU memory re- sources, especially in the training stage. quickly reach memory limits even on modern GPUs \
	Second, dilated convolutions introduce a coarse sub-sampling of fea- tures, which potentially leads to a loss of important details \
\pard\pardeftab720\partightenfactor0
\cf0 \kerning1\expnd0\expndtw0 	Filters are prohibited from accessing information at a finer scale than their original design.\cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl280\partightenfactor0
\ls7\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
Future direction\'a0(open research questions)\
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 	CRF-RNN, how to join inference using CRF and CNN(use just figure).\
	End to end regression tasks, i.e depth/optical flow prediction etc. \cf5 super-resolution, denoising, demosaicing, bottom-up saliency, keypoint detection\cf2 \
\
Should I read other papers related to this work? \
Just focus on the seminar paper, not dig much into detail in side papers.\
Answer questions like why CRF is relevant, augmention helps\'85\
\
25 Minute presentation, report is 20-22 slides\
\
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 1- Stanford\'92s paper on deconvolution\
\pard\pardeftab720\sl280\partightenfactor0
\cf2 2- Slide 9 : Challenges 1 : max pooling and downsampling was there to make sure the effective receptive field\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0is the whole image which is necessary for classification. You do not mention it in the\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0slide but it is nice to keep that in mind.\
\
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 3- Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation\
\pard\pardeftab720\partightenfactor0
\cf2 4- Sayfa 9\'92da kisaca diger cozumlerden bahset.\
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 5- Why atrous convolution is beneficial?\
	https://arxiv.org/pdf/1412.7062.pdf\
6- VGG is already trained to handle multiple scales\
8- Why do we need this instead of using deconvolutoion\
9- Implementation details(2 versions). Check 6 38 76 how they implemented filters\
10- 1 Slide showing advantages and disadvantages of using atrous filters.\
11- Check conference paper\
12- Check general architecture of the network\
13- Mention R-CNN idea and FCN idea.\'a0\
14- Large Field of View?\
15- Separate slides for each option on Table 7.\
Next Week: Next Week 3.3, 4.1 References: 3,6,16. 38, 76.\
Mention about weighted loss functions. Loss function, vgg, resnet, crf and cnn are treated significantly.\
Big slides for data sets.\
Vgg Net, and Resnet trained on image net.\
Tables for the contained val/train/set and some sample images.\
Don\'92t specify hyperparameters.\
Evaluation.\
Write the publication dates on the slides.\
Mention the difference between semantic segmentation and instance segmentation.\
Changes\
\
ADD FCN figure page 18, rename the title. \
How to implement taros filters?\
\
\pard\pardeftab720\sl300\sa240\partightenfactor0
\cf2 Deep Max-Pooling Convolutional Neural Networks are Deep Neural Networks (DNN) with con- volutional and max-pooling layers. Convolutional Neural Networks (CNN) can be traced back to the Neocognitron [1] in 1980. They were first successfully applied to relatively small tasks such as digit recognition [2], image interpretation [3] and object recognition [4]. Back then their size was greatly limited by the low computational power of available hardware. Since 2010, however, DNN have greatly profited from Graphics Processing Units (GPU). Simple GPU-based multilayer perceptrons (MLP) establised new state of the art results [5] on the MNIST handwritten digit dataset [4] when made both deep and large (augmenting the training set by artificial samples helped to avoid overfitting). 2011 saw the first implementation [6] of GPU-based DNN on the CUDA parallel computing platform [7]. This yielded new benchmark records on multiple object detection tasks. The field of Deep Learning with Neural Networks exploded. Multi-Column DNN [8] improved previous results by over 30% on many benchmarks including: handwritten digits (MNIST) [4] and Latin letters (NIST SD 19) [9]; Chinese characters (CASIA) [10]; traffic signs (GTSRB) [11]; natural images (CIFAR 10) [12]. Another flavor of DNN [13] greatly improved the accuracy on a subset of ImageNet [14]. Recently, Google parallelized a large DNN on a cluster with over 10000 CPU cores [15 \
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 \
\pard\pardeftab720\partightenfactor0
\cf6 Atrous convolution allows us to explicitly control how densely to compute feature responses in fully convolutional networks. Used in conjunction with bilinear interpolation, it offers an alternative to \cf7 \cb8 conv2d_transpose\cf6 \cb1  in dense prediction tasks such as semantic image segmentation, optical flow computation, or depth estimation. It also allows us to effectively enlarge the field of view of filters without increasing the number of parameters or the amount of computation.\
\
\pard\pardeftab720\sl300\sa240\partightenfactor0
\cf2 The presented module uses dilated convolutions to systematically aggregate multi- scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. exponential expansion of the receptive field without loss of resolution or coverage. \
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 Some recent work mistakenly referred to the dilated convolution operator itself as the algorithme a` trous. This is incorrect. The algorithme a` trous applies a filter at multiple scales to produce a signal decomposition. The algorithm uses dilated convolutions, but is not equivalent to the dilated convolution operator itself. \
\pard\pardeftab720\partightenfactor0
\cf0 \cb4 Evaluating the original ConvNet (with FC layers) independently across 224x224 crops of the 384x384 image in strides of 32 pixels gives an identical result to forwarding the converted ConvNet one time.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \
\pard\pardeftab720\sl300\sa240\partightenfactor0
\cf2 Should I mention \cf0 \kerning1\expnd0\expndtw0 learning rate, batch_size, NO iterations?\
Trimap Examples?\
Appendix e Q(x_i) figurine de ekle, CRF paperindan al.\
Check references for the tables/everything.\
TABLE 1/2 ?\
NO SNAPSHOT FOR TABLES!!!\
\pard\pardeftab720\partightenfactor0
\cf2 \expnd0\expndtw0\kerning0
TABLE CAPTIONS\
Resolution u kotu olan resimleri degistir.\
Caption u olan resimleri olmayanlarla degistir.\
Tablolari snapshot alma.\
\
Why do they use the validation set in test sessions at the first place?\
\
\pard\pardeftab720\partightenfactor0
\cf6 \
\
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 \
\pard\tx720\pardeftab720\sl280\partightenfactor0
\cf2 \
\
}